{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "PC",
      "provenance": [],
      "collapsed_sections": [
        "_1QO_BS18QkO",
        "6rVDdf_qrEEj"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/confifu/TryOnGAN-pytorch/blob/main/notebooks/PC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRGObN6jh4AC"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8exPpK_xh_6S"
      },
      "source": [
        "%%capture\n",
        "!pip install wandb==0.9.7"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6h7lj7JWiM-L",
        "outputId": "8efcb714-4a7e-4b86-bb79-732c113b3e3f"
      },
      "source": [
        "import wandb\n",
        "#wandb.login()\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTc7hnBMiWq-"
      },
      "source": [
        "#clone one\n",
        "\n",
        "!git clone -b PC-concat https://github.com/confifu/TryOnGAN-pytorch.git\n",
        "#!git clone -b PC-add https://github.com/confifu/TryOnGAN-pytorch.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1QO_BS18QkO"
      },
      "source": [
        "# Generate Dataset(Images)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rp8kAgToimZH"
      },
      "source": [
        "%%capture\n",
        "%cd /content/\n",
        "!gdown https://drive.google.com/uc?id=1r_Pz2gk1Sp2sjYS7cj9oYUMbLGo9EyZS\n",
        "!unzip /content/inshopclothes.zip\n",
        "!rm /content/inshopclothes.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_-nR76ViqBE"
      },
      "source": [
        "\n",
        "%cd /content/TryOnGAN-pytorch\n",
        "\n",
        "!python dataset_tool.py --source=/content/train --dest=/content/my_dataset --width=256 --height=256\n",
        "!rm -rf /content/train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rVDdf_qrEEj"
      },
      "source": [
        "# Generate pose keypoints"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2H0k83T-_Kr"
      },
      "source": [
        "%%capture\n",
        "'''\n",
        "!mkdir /content/new_images\n",
        "!unzip /content/my_dataset.zip -d \"/content/new_images/\"\n",
        "!mkdir /content/flat_images\n",
        "!find /content/new_images -mindepth 2 -type f -exec mv -t /content/flat_images -i '{}' +\n",
        "!rm -rf /content/new_images\n",
        "!mv /content/flat_images /content/new_images\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgeUUGXJdXeC"
      },
      "source": [
        "'''\n",
        "!unzip /content/TestImages.zip\n",
        "!mv /content/TestImages /content/new_images\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsJTAt5r91PW"
      },
      "source": [
        "#create pose keypoints\n",
        "'''\n",
        "\n",
        "! pip install pyyaml==5.2\n",
        "! pip install scipy==1.1.0\n",
        "! pip install torch==1.2.0 torchvision==0.4.0\n",
        "! pip install pillow==6.2.2\n",
        "!python -m pip install cython\n",
        "!sudo apt-get install libyaml-dev\n",
        "\n",
        "import yaml, scipy, os, torch\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "os.chdir('/content/')\n",
        "!rm -rf /content/AlphaPose\n",
        "!git clone https://github.com/MVIG-SJTU/AlphaPose.git\n",
        "\n",
        "os.chdir('/content/AlphaPose')\n",
        "! python setup.py build develop\n",
        "\n",
        "!gdown https://drive.google.com/uc?id=1D47msNOOiJKvPOXlnpyzdKA3k6E97NTC\n",
        "!gdown https://drive.google.com/uc?id=1nlnuYfGNuHWZztQHXwVZSL_FvfE551pA\n",
        "!gdown https://drive.google.com/uc?id=1kQhnMRURFiy7NsdS8EFL-8vtqEXOgECn\n",
        "\n",
        "!mkdir /content/AlphaPose/detector/yolo/data\n",
        "!mkdir /content/AlphaPose/detector/tracker/data\n",
        "\n",
        "!mv /content/AlphaPose/yolov3-spp.weights /content/AlphaPose/detector/yolo/data/yolov3-spp.weights\n",
        "!mv /content/AlphaPose/jde.1088x608.uncertainty.pt /content/AlphaPose/detector/tracker/data/JDE-1088x608-uncertainty\n",
        "!mv /content/AlphaPose/fast_res50_256x192.pth /content/AlphaPose/pretrained_models/fast_res50_256x192.pth\n",
        "\n",
        "!(python3 scripts/demo_inference.py \\\n",
        "--cfg configs/coco/resnet/256x192_res50_lr1e-3_1x.yaml \\\n",
        "--checkpoint pretrained_models/fast_res50_256x192.pth \\\n",
        "--indir /content/new_images/ \\\n",
        "--sp \\\n",
        "--qsize 128)\n",
        "# result json and rendered images are saved here:\n",
        "\n",
        "\n",
        "! ls examples/res/\n",
        "\n",
        "import json\n",
        "def createPoseAnnotation(jsonFileName):\n",
        "    \n",
        "    imageSize = 256.0\n",
        "    heatMapSize = 64.0\n",
        "    ratio = heatMapSize / imageSize\n",
        "    jsonFile = open(jsonFileName)\n",
        "    data = json.load(jsonFile)\n",
        "    print(\"Number of pose keypoints generated \", len(data))\n",
        "\n",
        "    files = []\n",
        "    keypoints = []\n",
        "    for i in range(len(data)):\n",
        "        name = data[i]['image_id']\n",
        "        files.append(name)\n",
        "\n",
        "        keypoint = data[i]['keypoints']\n",
        "        string = ':'.join(str(e) for e in keypoint)\n",
        "        keypoints.append(string)\n",
        "\n",
        "    \n",
        "    data = {'name' : files,\n",
        "            'keypoints' : keypoints}\n",
        "\n",
        "    newdf = pd.DataFrame.from_dict(data)\n",
        "    newdf.to_csv('/content/pose-annotations.csv', index = False)\n",
        "\n",
        "    jsonFile.close()\n",
        "\n",
        "createPoseAnnotation('/content/AlphaPose/examples/res/alphapose-results.json')\n",
        "'''\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqaoZjihrcov"
      },
      "source": [
        "# Download pose keypoints from gdrive\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFFpSsbaruLH"
      },
      "source": [
        "%cd /content\n",
        "!gdown https://drive.google.com/uc?id=1XryABeNxvzsdjEY7j4ed2m4G-we0n0md"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBx0rihbrzpW"
      },
      "source": [
        "# Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0tNYGLeLG2m"
      },
      "source": [
        "\n",
        "%cd /content/TryOnGAN-pytorch\n",
        "\n",
        "!wget https://github.com/ninja-build/ninja/releases/download/v1.8.2/ninja-linux.zip\n",
        "!sudo unzip ninja-linux.zip -d /usr/local/bin/\n",
        "!sudo update-alternatives --install /usr/bin/ninja ninja /usr/local/bin/ninja 1 --force"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZ6yeeY596-5"
      },
      "source": [
        "!pip install torch==1.8.1 torchvision==0.9.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTDR6Hp9iwdz"
      },
      "source": [
        "#for training ffhq checkpoint model\n",
        "%cd /content/TryOnGAN-pytorch\n",
        "!(python train.py \\\n",
        "--outdir=/content/outdir \\\n",
        "--data=/content/my_dataset.zip \\\n",
        "--posefile=/content/pose-annotations.csv \\\n",
        "--resume=/gdrive/MyDrive/ada-tryongan/best_checkpoints/PC-add-scratch-network-snapshot-002040.pkl \\\n",
        "--mirror=1 \\\n",
        "--gpus=1 \\\n",
        "--seed=600 \\\n",
        "--batch=32 \\\n",
        "--aug=ada \\\n",
        "--snap=1 \\\n",
        "--project=ada-uncon-scratch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3QwoIN7Bwq8"
      },
      "source": [
        "function ClickConnect(){\n",
        "    console.log(\"Clicked on connect button\"); \n",
        "    document.querySelector(\"colab-connect-button\").click()\n",
        "}\n",
        "setInterval(ClickConnect,60000)"
      ]
    }
  ]
}
